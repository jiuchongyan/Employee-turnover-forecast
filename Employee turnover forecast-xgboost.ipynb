{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "configured-knock",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:54:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { boosting_type, subsample_freq } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-auc:0.86321\tvalid-auc:0.69792\n",
      "[25]\ttrain-auc:0.96942\tvalid-auc:0.77043\n",
      "[50]\ttrain-auc:0.97321\tvalid-auc:0.77988\n",
      "[75]\ttrain-auc:0.98354\tvalid-auc:0.78129\n",
      "[100]\ttrain-auc:0.98737\tvalid-auc:0.78075\n",
      "[125]\ttrain-auc:0.99079\tvalid-auc:0.78370\n",
      "[150]\ttrain-auc:0.99372\tvalid-auc:0.78828\n",
      "[175]\ttrain-auc:0.99663\tvalid-auc:0.79199\n",
      "[200]\ttrain-auc:0.99797\tvalid-auc:0.79745\n",
      "[225]\ttrain-auc:0.99889\tvalid-auc:0.80170\n",
      "[250]\ttrain-auc:0.99932\tvalid-auc:0.80792\n",
      "[275]\ttrain-auc:0.99964\tvalid-auc:0.81109\n",
      "[300]\ttrain-auc:0.99984\tvalid-auc:0.81360\n",
      "[325]\ttrain-auc:0.99988\tvalid-auc:0.81436\n",
      "[350]\ttrain-auc:0.99994\tvalid-auc:0.81545\n",
      "[375]\ttrain-auc:0.99996\tvalid-auc:0.81775\n",
      "[400]\ttrain-auc:0.99999\tvalid-auc:0.81884\n",
      "[425]\ttrain-auc:1.00000\tvalid-auc:0.81982\n",
      "[450]\ttrain-auc:1.00000\tvalid-auc:0.82102\n",
      "[475]\ttrain-auc:1.00000\tvalid-auc:0.82146\n",
      "[500]\ttrain-auc:1.00000\tvalid-auc:0.82276\n",
      "[525]\ttrain-auc:1.00000\tvalid-auc:0.82288\n",
      "[550]\ttrain-auc:1.00000\tvalid-auc:0.82266\n",
      "[575]\ttrain-auc:1.00000\tvalid-auc:0.82244\n",
      "[600]\ttrain-auc:1.00000\tvalid-auc:0.82156\n",
      "[625]\ttrain-auc:1.00000\tvalid-auc:0.82222\n",
      "[650]\ttrain-auc:1.00000\tvalid-auc:0.82047\n",
      "[675]\ttrain-auc:1.00000\tvalid-auc:0.82135\n",
      "[700]\ttrain-auc:1.00000\tvalid-auc:0.82080\n",
      "[725]\ttrain-auc:1.00000\tvalid-auc:0.82069\n",
      "[747]\ttrain-auc:1.00000\tvalid-auc:0.82113\n",
      "[0.09786214 0.01218768 0.02586609 0.06123629 0.8942016  0.09218413\n",
      " 0.38299137 0.02867225 0.01293043 0.24023011 0.00941281 0.06231796\n",
      " 0.0304169  0.8600953  0.01308591 0.00246955 0.03389173 0.03196572\n",
      " 0.02181524 0.06674897 0.6086586  0.02170851 0.00745412 0.00895304\n",
      " 0.43687582 0.28512448 0.03241172 0.01234874 0.58948714 0.0135645\n",
      " 0.02445943 0.02092847 0.09306942 0.0865141  0.01260401 0.01195602\n",
      " 0.05067321 0.0208525  0.10165989 0.01952917 0.04833253 0.02887583\n",
      " 0.01741921 0.04608994 0.02688635 0.41831312 0.14220856 0.00564119\n",
      " 0.8838029  0.60149163 0.11609556 0.48752412 0.07367554 0.04216341\n",
      " 0.44883263 0.01922403 0.00931882 0.02741617 0.00618645 0.27963907\n",
      " 0.01266926 0.04183318 0.02506381 0.01306745 0.2536405  0.0290067\n",
      " 0.04050703 0.01962621 0.06111515 0.03745988 0.10484356 0.15328561\n",
      " 0.03288589 0.01076847 0.00851169 0.06041039 0.03697018 0.02053599\n",
      " 0.12253287 0.0067977  0.00547275 0.00956767 0.01869638 0.02196505\n",
      " 0.02494157 0.02395743 0.02219203 0.10718795 0.03871349 0.05113653\n",
      " 0.6909579  0.011228   0.0336381  0.31440887 0.01351982 0.01245926\n",
      " 0.0439203  0.27709714 0.0051269  0.02323591 0.0557154  0.17952152\n",
      " 0.28392512 0.02756418 0.00871953 0.01167256 0.05261204 0.3716304\n",
      " 0.07412601 0.02877065 0.08818911 0.03727861 0.02388857 0.02160259\n",
      " 0.06226772 0.02004434 0.01021511 0.01719634 0.0114458  0.00340479\n",
      " 0.03556757 0.00820114 0.01244147 0.7403781  0.21519029 0.02281873\n",
      " 0.00571065 0.03567685 0.05077245 0.01364374 0.00943408 0.28686818\n",
      " 0.4413581  0.14214207 0.07288971 0.10824947 0.31438535 0.03071557\n",
      " 0.02271481 0.01845335 0.01849376 0.02721643 0.09105726 0.05980733\n",
      " 0.08837354 0.01623834 0.02423992 0.02186909 0.02787954 0.01539248\n",
      " 0.01869722 0.06351258 0.0175922  0.06550454 0.0556994  0.0203865\n",
      " 0.02439994 0.03963058 0.06494902 0.01916341 0.3421369  0.00780861\n",
      " 0.14407489 0.7511544  0.02441674 0.09680366 0.39688116 0.0074411\n",
      " 0.00658271 0.01698731 0.02527939 0.02944089 0.02259103 0.09961047\n",
      " 0.01659209 0.08413353 0.01190676 0.0806293  0.09462865 0.06081465\n",
      " 0.00486974 0.00856059 0.00476967 0.6341849  0.01422321 0.01562321\n",
      " 0.13521366 0.01860962 0.07680228 0.05113779 0.32331222 0.821395\n",
      " 0.02656976 0.00692786 0.02859896 0.03259793 0.01272676 0.00830655\n",
      " 0.6041219  0.04187121 0.05800055 0.0153593  0.08787359 0.01170047\n",
      " 0.09744901 0.04101016 0.43973958 0.0086881  0.05294676 0.01779358\n",
      " 0.04332599 0.01931433 0.01047382 0.0247216  0.01810116 0.01218717\n",
      " 0.00901393 0.15303752 0.03013066 0.27888477 0.04000366 0.17226148\n",
      " 0.7114328  0.07731784 0.1269596  0.01569375 0.02330425 0.42641073\n",
      " 0.6149384  0.04109706 0.0073052  0.14849783 0.0084153  0.02624851\n",
      " 0.00679692 0.11487613 0.18360867 0.00490201 0.02210152 0.01739481\n",
      " 0.03613382 0.02972494 0.01562071 0.02310945 0.04937544 0.01195017\n",
      " 0.0293659  0.27127436 0.01474369 0.04203267 0.03668444 0.04059765\n",
      " 0.14583118 0.02082313 0.14893892 0.03388826 0.01267435 0.88840866\n",
      " 0.06000567 0.50817835 0.07328639 0.03472536 0.08403729 0.02508438\n",
      " 0.05404326 0.17361046 0.01018492 0.07591748 0.09788199 0.00652103\n",
      " 0.02579705 0.00899525 0.0174596  0.01576482 0.00891876 0.06433096\n",
      " 0.07892575 0.1221281  0.06782581 0.0729234  0.13703078 0.04246779\n",
      " 0.01868138 0.01130627 0.06066829 0.18631783 0.00269481 0.05458586\n",
      " 0.01996991 0.02210242 0.01714563 0.40021786 0.00657608 0.03429839]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "train=pd.read_csv('train.csv',index_col=0)\n",
    "test=pd.read_csv('test.csv',index_col=0)\n",
    "\n",
    "#print(train['Attrition'].value_counts())\n",
    "# 处理Attrition字段\n",
    "train['Attrition']=train['Attrition'].map(lambda x:1 if x=='Yes' else 0)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# 查看数据是否有空值\n",
    "#print(train.isna().sum())\n",
    "\n",
    "# 去掉没用的列 员工号码，标准工时（=80）\n",
    "train = train.drop(['EmployeeNumber', 'StandardHours'], axis=1)\n",
    "test = test.drop(['EmployeeNumber', 'StandardHours'], axis=1)\n",
    "\n",
    "# 对于分类特征进行特征值编码\n",
    "attr=['Age','BusinessTravel','Department','Education','EducationField','Gender','JobRole','MaritalStatus','Over18','OverTime']\n",
    "lbe_list=[]\n",
    "for feature in attr:\n",
    "    lbe=LabelEncoder()\n",
    "    train[feature]=lbe.fit_transform(train[feature])\n",
    "    test[feature]=lbe.transform(test[feature])\n",
    "    lbe_list.append(lbe)\n",
    "#train.to_csv('temp.csv')\n",
    "#print(train)\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "param = {'boosting_type':'gbdt',\n",
    "                         'objective' : 'binary:logistic', #\n",
    "                         'eval_metric' : 'auc',\n",
    "                         'eta' : 0.01,\n",
    "                         'max_depth' : 15,\n",
    "                         'colsample_bytree':0.8,\n",
    "                         'subsample': 0.9,\n",
    "                         'subsample_freq': 8,\n",
    "                         'alpha': 0.6,\n",
    "                         'lambda': 0,\n",
    "        }\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(train.drop('Attrition',axis=1), train['Attrition'], test_size=0.2, random_state=42)\n",
    "\n",
    "train_data = xgb.DMatrix(X_train, label=y_train)\n",
    "valid_data = xgb.DMatrix(X_valid, label=y_valid)\n",
    "test_data = xgb.DMatrix(test)\n",
    "\n",
    "model = xgb.train(param, train_data, evals=[(train_data, 'train'), (valid_data, 'valid')], num_boost_round = 10000, early_stopping_rounds=200, verbose_eval=25)\n",
    "predict = model.predict(test_data)\n",
    "test['Attrition']=predict\n",
    "print(predict)\n",
    "# 转化为二分类输出\n",
    "#test['Attrition']=test['Attrition'].map(lambda x:1 if x>=0.5 else 0)\n",
    "test[['Attrition']].to_csv('submit_xgb.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charged-rachel",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
